{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-omic Dataset: Latent representation using Denoising Autoencoders\n",
    "- Load Data\n",
    "- Add Swap Noise to Data\n",
    "- Normalize Data\n",
    "- Define Autoencoder Model\n",
    "- Train Autoencoder with normalized noisy dataset\n",
    "- Use transformed dataset for classification\n",
    "- Use transformed dataset for clustering\n",
    "- Evaluation and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swapping: 65 rows.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random as rn\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "rn.seed(1)\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "# Load Data\n",
    "X_renal_data = pd.read_csv('./x_exp_renal.csv', sep='\\t') # Dataset has Donor ID as first column\n",
    "y_renal_data = pd.read_csv('./y_renal.csv', sep=',') # Dataset has Donor ID on first column and Label on second column.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_renal_data.iloc[:,1:],y_renal_data[\"label\"],test_size=0.2, random_state=1) # Drop the Donor ID column from both datasets\n",
    "\n",
    "X_swapped = X_train\n",
    "\n",
    "# Add swap noise to training dataset\n",
    "# Swap Noise 15% - 1700*0.15 = 255\n",
    "swap_noise = 0.15\n",
    "num_swaps = round(X_train.shape[0]*swap_noise)\n",
    "print(f\"swapping: {num_swaps} rows.\")\n",
    "\n",
    "for col in range(X_train.shape[1]):\n",
    "    to_swap_rows = np.random.randint(X_train.shape[0], size=num_swaps)\n",
    "    sample_rows = np.random.randint(X_train.shape[0], size=num_swaps)\n",
    "    \n",
    "    X_swapped.iloc[to_swap_rows,col] = X_train.iloc[sample_rows,col].values\n",
    "\n",
    "# Normalization of data sets\n",
    "# Data Scaling MinMax\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train_swapped = X_swapped\n",
    "X_train_norm = X_train\n",
    "X_test_norm = X_test\n",
    "\n",
    "X_train_swapped = pd.DataFrame(scaler.fit_transform(X_train_swapped))\n",
    "X_train_norm = pd.DataFrame(scaler.fit_transform(X_train_norm))\n",
    "X_test_norm = pd.DataFrame(scaler.transform(X_test_norm))\n",
    "\n",
    "# We will use \"X_train_swapped\" as input training dataset and \"X_train_norm\" as output for the loss function of the Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression: 820.08\n"
     ]
    }
   ],
   "source": [
    "## AUTOENCODER MODEL\n",
    "# Define the model using the keras functional API\n",
    "def build_autoencoder(encoding_dim: int, number_features: int, regularizer: tf.keras.regularizers.Regularizer, dropout: float):\n",
    "    \"\"\"Two-input autoencoder build function\n",
    "       Parameters: encoding_dim: Size of the latent space (bottleneck layer size).\n",
    "                   number_features: Tuple with the sizes of the two inputs.\n",
    "                   regularizer: keras regularizer object\n",
    "       Returns the 3 models: full autoencoder, the encoder part and the decoder part\n",
    "    \"\"\"\n",
    "    if dropout > 1:\n",
    "        dropout = 1\n",
    "    elif dropout < 0:\n",
    "        dropout = 0\n",
    "    # this is the reduction of our encoded representations, in times.\n",
    "    print(f\"Compression: {number_features/encoding_dim}\")\n",
    "\n",
    "    first_layer_size = number_features/40\n",
    "    second_layer_size = number_features/150\n",
    "    \n",
    "    ## ENCODER\n",
    "    # encoder first input placeholder.\n",
    "    first_input = layers.Input(shape=(number_features))\n",
    "    # encoder first Hidden Layer - H1\n",
    "    H1 = layers.Dense(first_layer_size, activation='relu', kernel_regularizer=regularizer)(first_input)\n",
    "    # encoder first Dropout Layer - D1\n",
    "    D1 = layers.Dropout(dropout)(H1)\n",
    "    # encoder first Batch Normalization Layer - BN1\n",
    "    BN1 = layers.BatchNormalization()(D1)\n",
    "    # encoder second Hidden Layer - H2\n",
    "    H2 = layers.Dense(second_layer_size, activation='relu', kernel_regularizer=regularizer)(BN1)\n",
    "    # encoder second Dropout Layer - D2\n",
    "    D2 = layers.Dropout(dropout)(H2)\n",
    "    # encoder first path second Batch Normalization Layer - BN2\n",
    "    BN2 = layers.BatchNormalization()(D2)\n",
    "\n",
    "   \n",
    "    ## BOTTLENECK \n",
    "    bottleneck = layers.Dense(encoding_dim, activation='relu', kernel_regularizer=regularizer)(BN2)\n",
    "\n",
    "    # this model maps an input to its encoded representation\n",
    "    encoder = keras.models.Model(first_input, bottleneck, name='encoder')\n",
    "\n",
    "    ## DECODER\n",
    "    # Decoder Input Layer - Encoding dimension\n",
    "    encoded_input = layers.Input(shape=(encoding_dim,))\n",
    "    # decoder first Dropout Layer - D3\n",
    "    D3 = layers.Dropout(dropout)(encoded_input)\n",
    "    # decoder first Batch Normalization Layer - BN3 \n",
    "    BN3 = layers.BatchNormalization()(D3)\n",
    "    # decoder first Hidden Layer - H3\n",
    "    H3 = layers.Dense(second_layer_size, activation='relu', kernel_regularizer=regularizer)(BN3)\n",
    "    # decoder second Dropout Layer - D4\n",
    "    D4 = layers.Dropout(dropout)(H3)\n",
    "    # decoder second Batch Normalization Layer - BN4 \n",
    "    BN4 = layers.BatchNormalization()(D4)\n",
    "    # decoder reconstruction layer - O1\n",
    "    O1 = layers.Dense(number_features, activation='sigmoid')(BN4)\n",
    "\n",
    "    # create the decoder model\n",
    "    decoder = keras.models.Model(encoded_input, O1)\n",
    "\n",
    "    # create the full autoencoder\n",
    "    encoder_model = encoder(first_input)\n",
    "    decoder_model = decoder(encoder_model)\n",
    "\n",
    "    autoencoder = keras.models.Model(first_input, decoder_model, name=\"autoencoder\")\n",
    "    \n",
    "    return autoencoder, encoder, decoder\n",
    "\n",
    "# Set Optimizer: Adam with learning rate=0.001\n",
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "# Set Early Stop Callback\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=10,  mode='auto', baseline=None, restore_best_weights=False, verbose=1)\n",
    "\n",
    "## Call autoencoder build function and get the AE, the encoder and the decoder.\n",
    "autoencoder, encoder, decoder = build_autoencoder(encoding_dim=25, number_features=X_train_swapped.shape[1], regularizer=tf.keras.regularizers.l1_l2(0.0001,0), dropout=0.5)\n",
    "# Compile the autoencoder using Mean Square Error loss function.\n",
    "autoencoder.compile(optimizer=optimizer,\n",
    "                        loss=\"mse\",\n",
    "                        metrics=['mse'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 433 samples, validate on 109 samples\n",
      "Epoch 1/80\n",
      "433/433 [==============================] - 6s 14ms/sample - loss: 4.8831 - mse: 0.1491 - val_loss: 1.7112 - val_mse: 0.2283\n",
      "Epoch 2/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 1.4148 - mse: 0.1458 - val_loss: 1.0006 - val_mse: 0.2241\n",
      "Epoch 3/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.8331 - mse: 0.1405 - val_loss: 0.8140 - val_mse: 0.2206\n",
      "Epoch 4/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.6598 - mse: 0.1312 - val_loss: 0.6832 - val_mse: 0.2025\n",
      "Epoch 5/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.5779 - mse: 0.1152 - val_loss: 0.6791 - val_mse: 0.1851\n",
      "Epoch 6/80\n",
      "433/433 [==============================] - 5s 11ms/sample - loss: 0.5714 - mse: 0.0936 - val_loss: 0.6651 - val_mse: 0.1580\n",
      "Epoch 7/80\n",
      "433/433 [==============================] - 5s 11ms/sample - loss: 0.6361 - mse: 0.0704 - val_loss: 0.7551 - val_mse: 0.1319\n",
      "Epoch 8/80\n",
      "433/433 [==============================] - 6s 14ms/sample - loss: 0.6778 - mse: 0.0481 - val_loss: 0.7862 - val_mse: 0.1159\n",
      "Epoch 9/80\n",
      "433/433 [==============================] - 5s 12ms/sample - loss: 0.7437 - mse: 0.0364 - val_loss: 0.7932 - val_mse: 0.1024\n",
      "Epoch 10/80\n",
      "433/433 [==============================] - 4s 10ms/sample - loss: 0.7172 - mse: 0.0270 - val_loss: 0.7812 - val_mse: 0.0974\n",
      "Epoch 11/80\n",
      "433/433 [==============================] - 5s 11ms/sample - loss: 0.6732 - mse: 0.0229 - val_loss: 0.6990 - val_mse: 0.0956\n",
      "Epoch 12/80\n",
      "433/433 [==============================] - 4s 10ms/sample - loss: 0.5896 - mse: 0.0194 - val_loss: 0.6187 - val_mse: 0.0959\n",
      "Epoch 13/80\n",
      "433/433 [==============================] - 5s 11ms/sample - loss: 0.5687 - mse: 0.0194 - val_loss: 0.7375 - val_mse: 0.0932\n",
      "Epoch 14/80\n",
      "433/433 [==============================] - 4s 10ms/sample - loss: 0.6492 - mse: 0.0179 - val_loss: 0.7245 - val_mse: 0.0933\n",
      "Epoch 15/80\n",
      "433/433 [==============================] - 5s 11ms/sample - loss: 0.6229 - mse: 0.0180 - val_loss: 0.7028 - val_mse: 0.0931\n",
      "Epoch 16/80\n",
      "433/433 [==============================] - 5s 12ms/sample - loss: 0.6323 - mse: 0.0174 - val_loss: 0.7009 - val_mse: 0.0926\n",
      "Epoch 17/80\n",
      "433/433 [==============================] - 5s 11ms/sample - loss: 0.6081 - mse: 0.0181 - val_loss: 0.6671 - val_mse: 0.0945\n",
      "Epoch 18/80\n",
      "433/433 [==============================] - 5s 11ms/sample - loss: 0.5607 - mse: 0.0174 - val_loss: 0.6278 - val_mse: 0.0940\n",
      "Epoch 19/80\n",
      "433/433 [==============================] - 5s 11ms/sample - loss: 0.5384 - mse: 0.0169 - val_loss: 0.6377 - val_mse: 0.0943\n",
      "Epoch 20/80\n",
      "433/433 [==============================] - 4s 10ms/sample - loss: 0.6516 - mse: 0.0169 - val_loss: 0.7695 - val_mse: 0.0909\n",
      "Epoch 21/80\n",
      "433/433 [==============================] - 4s 10ms/sample - loss: 0.6651 - mse: 0.0164 - val_loss: 0.6516 - val_mse: 0.0951\n",
      "Epoch 22/80\n",
      "433/433 [==============================] - 5s 11ms/sample - loss: 0.5017 - mse: 0.0158 - val_loss: 0.5362 - val_mse: 0.0956\n",
      "Epoch 23/80\n",
      "433/433 [==============================] - 5s 11ms/sample - loss: 0.4819 - mse: 0.0167 - val_loss: 0.6122 - val_mse: 0.0935\n",
      "Epoch 24/80\n",
      "433/433 [==============================] - 4s 10ms/sample - loss: 0.5414 - mse: 0.0159 - val_loss: 0.6498 - val_mse: 0.0933\n",
      "Epoch 25/80\n",
      "433/433 [==============================] - 4s 10ms/sample - loss: 0.6053 - mse: 0.0161 - val_loss: 0.6979 - val_mse: 0.0935\n",
      "Epoch 26/80\n",
      "433/433 [==============================] - 5s 12ms/sample - loss: 0.5475 - mse: 0.0158 - val_loss: 0.5460 - val_mse: 0.0947\n",
      "Epoch 27/80\n",
      "433/433 [==============================] - 5s 11ms/sample - loss: 0.4320 - mse: 0.0162 - val_loss: 0.4785 - val_mse: 0.0939\n",
      "Epoch 28/80\n",
      "433/433 [==============================] - 5s 12ms/sample - loss: 0.3887 - mse: 0.0156 - val_loss: 0.4650 - val_mse: 0.0933\n",
      "Epoch 29/80\n",
      "433/433 [==============================] - 6s 13ms/sample - loss: 0.3854 - mse: 0.0152 - val_loss: 0.4750 - val_mse: 0.0932\n",
      "Epoch 30/80\n",
      "433/433 [==============================] - 5s 12ms/sample - loss: 0.4778 - mse: 0.0157 - val_loss: 0.5943 - val_mse: 0.0931\n",
      "Epoch 31/80\n",
      "433/433 [==============================] - 4s 10ms/sample - loss: 0.4832 - mse: 0.0156 - val_loss: 0.5441 - val_mse: 0.0912\n",
      "Epoch 32/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.4544 - mse: 0.0157 - val_loss: 0.5359 - val_mse: 0.0926\n",
      "Epoch 33/80\n",
      "433/433 [==============================] - 4s 10ms/sample - loss: 0.5705 - mse: 0.0158 - val_loss: 0.6708 - val_mse: 0.0919\n",
      "Epoch 34/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.5743 - mse: 0.0153 - val_loss: 0.5790 - val_mse: 0.0955\n",
      "Epoch 35/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.5040 - mse: 0.0153 - val_loss: 0.5897 - val_mse: 0.0909\n",
      "Epoch 36/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.6112 - mse: 0.0149 - val_loss: 0.6563 - val_mse: 0.0940\n",
      "Epoch 37/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.5228 - mse: 0.0155 - val_loss: 0.5381 - val_mse: 0.0942\n",
      "Epoch 38/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.4281 - mse: 0.0150 - val_loss: 0.4688 - val_mse: 0.0929\n",
      "Epoch 39/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.3957 - mse: 0.0153 - val_loss: 0.4507 - val_mse: 0.0914\n",
      "Epoch 40/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.4641 - mse: 0.0152 - val_loss: 0.7557 - val_mse: 0.0916\n",
      "Epoch 41/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.6292 - mse: 0.0148 - val_loss: 0.6193 - val_mse: 0.0928\n",
      "Epoch 42/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.5053 - mse: 0.0150 - val_loss: 0.5257 - val_mse: 0.0936\n",
      "Epoch 43/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.4021 - mse: 0.0152 - val_loss: 0.4525 - val_mse: 0.0948\n",
      "Epoch 44/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.3682 - mse: 0.0150 - val_loss: 0.5033 - val_mse: 0.0919\n",
      "Epoch 45/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.4403 - mse: 0.0156 - val_loss: 0.5265 - val_mse: 0.0918\n",
      "Epoch 46/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.5056 - mse: 0.0152 - val_loss: 0.5392 - val_mse: 0.0924\n",
      "Epoch 47/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.4088 - mse: 0.0152 - val_loss: 0.4591 - val_mse: 0.0930\n",
      "Epoch 48/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.3886 - mse: 0.0149 - val_loss: 0.4656 - val_mse: 0.0937\n",
      "Epoch 49/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.3621 - mse: 0.0150 - val_loss: 0.4181 - val_mse: 0.0936\n",
      "Epoch 50/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.3454 - mse: 0.0149 - val_loss: 0.4136 - val_mse: 0.0940\n",
      "Epoch 51/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.3367 - mse: 0.0149 - val_loss: 0.4089 - val_mse: 0.0936\n",
      "Epoch 52/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.3256 - mse: 0.0150 - val_loss: 0.4010 - val_mse: 0.0933\n",
      "Epoch 53/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.3103 - mse: 0.0147 - val_loss: 0.3705 - val_mse: 0.0947\n",
      "Epoch 54/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.2942 - mse: 0.0145 - val_loss: 0.3807 - val_mse: 0.0944\n",
      "Epoch 55/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.3197 - mse: 0.0146 - val_loss: 0.4029 - val_mse: 0.0904\n",
      "Epoch 56/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.3295 - mse: 0.0149 - val_loss: 0.4209 - val_mse: 0.0926\n",
      "Epoch 57/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.4442 - mse: 0.0148 - val_loss: 0.5268 - val_mse: 0.0912\n",
      "Epoch 58/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.4258 - mse: 0.0146 - val_loss: 0.4572 - val_mse: 0.0914\n",
      "Epoch 59/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.3421 - mse: 0.0149 - val_loss: 0.3667 - val_mse: 0.0925\n",
      "Epoch 60/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.2824 - mse: 0.0145 - val_loss: 0.3458 - val_mse: 0.0931\n",
      "Epoch 61/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.2440 - mse: 0.0145 - val_loss: 0.3011 - val_mse: 0.0916\n",
      "Epoch 62/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.2236 - mse: 0.0142 - val_loss: 0.3098 - val_mse: 0.0930\n",
      "Epoch 63/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.2300 - mse: 0.0145 - val_loss: 0.3109 - val_mse: 0.0923\n",
      "Epoch 64/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.2264 - mse: 0.0144 - val_loss: 0.2852 - val_mse: 0.0946\n",
      "Epoch 65/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.1986 - mse: 0.0142 - val_loss: 0.2984 - val_mse: 0.0902\n",
      "Epoch 66/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.2393 - mse: 0.0144 - val_loss: 0.3341 - val_mse: 0.0904\n",
      "Epoch 67/80\n",
      "433/433 [==============================] - 4s 10ms/sample - loss: 0.2531 - mse: 0.0142 - val_loss: 0.3258 - val_mse: 0.0907\n",
      "Epoch 68/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.2386 - mse: 0.0145 - val_loss: 0.3209 - val_mse: 0.0907\n",
      "Epoch 69/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.2409 - mse: 0.0145 - val_loss: 0.3147 - val_mse: 0.0904\n",
      "Epoch 70/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.2357 - mse: 0.0142 - val_loss: 0.3246 - val_mse: 0.0904\n",
      "Epoch 71/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.2636 - mse: 0.0144 - val_loss: 0.3278 - val_mse: 0.0915\n",
      "Epoch 72/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.2492 - mse: 0.0145 - val_loss: 0.3195 - val_mse: 0.0917\n",
      "Epoch 73/80\n",
      "433/433 [==============================] - 4s 9ms/sample - loss: 0.2296 - mse: 0.0145 - val_loss: 0.3369 - val_mse: 0.0929\n",
      "Epoch 74/80\n",
      "433/433 [==============================] - 4s 10ms/sample - loss: 0.2547 - mse: 0.0144 - val_loss: 0.3299 - val_mse: 0.0902\n",
      "Epoch 75/80\n",
      "433/433 [==============================] - 5s 12ms/sample - loss: 0.2540 - mse: 0.0143 - val_loss: 0.3004 - val_mse: 0.0930\n",
      "Epoch 76/80\n",
      "433/433 [==============================] - 4s 10ms/sample - loss: 0.2094 - mse: 0.0143 - val_loss: 0.2764 - val_mse: 0.0924\n",
      "Epoch 77/80\n",
      "433/433 [==============================] - 5s 10ms/sample - loss: 0.1986 - mse: 0.0142 - val_loss: 0.2708 - val_mse: 0.0929\n",
      "Epoch 78/80\n",
      "433/433 [==============================] - 4s 10ms/sample - loss: 0.1994 - mse: 0.0142 - val_loss: 0.2878 - val_mse: 0.0902\n",
      "Epoch 79/80\n",
      "433/433 [==============================] - 4s 10ms/sample - loss: 0.2097 - mse: 0.0143 - val_loss: 0.3013 - val_mse: 0.0903\n",
      "Epoch 80/80\n",
      "433/433 [==============================] - 6s 15ms/sample - loss: 0.2278 - mse: 0.0140 - val_loss: 0.2912 - val_mse: 0.0903\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEICAYAAAB25L6yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3wVddb48c9JBxJ6lBIgwCpVCCFib2DXtbIqa6+rrgV118X9uY9ldVf3cRF317U8KlgQdcW2qFhRLIgUAUVAQHoNQVqkpJzfH2duchPSSbgDnPfrNa/ce6edmXtz5jtnvneuqCrOOefCKy7WATjnnKuaJ2rnnAs5T9TOORdynqidcy7kPFE751zIeaJ2zrmQ80S9jxIRFZFfxDqO+iYio0Tkvl2Y/3ER+VN9xlSfRGS2iBxb39OG3a6+r3u6hFgHECYi8gnQF2ijqttrMZ8CB6jqgoaKLcxE5DLgKlU9Mtax7CpVvbYhlisimcAiIFFVC+u6HFXt1RDTunDzFnUg+Ec6ClDgjJgGE2Iistce3EUkPsbr32v3rds1nqhLXQJ8BYwCLo0eISKfiMhVUc8vE5HPg8cTg5dnisgWETk/eP1qEVkgIutF5C0RaRc1f3cR+SAYN09EzosaN0pEHhWRt0Vks4hMFpGuUeN7Rc27RkT+GLyeLCIjRGRlMIwQkeSo+X4vIquCcVeU275kEXlIRJYGy3xcRBoF444VkeUi8gcRWQ2MrM1OFZF2wfavD/bH1VHjBojIVBHZFKx3ePB6ioi8ICJ5IrJBRKaIyP6VLL+fiEwP9tXLQEpF71PUayUln2BfPyYi74hIPnBc9Cl21LbfJiJrg/13edSyWonIf4P4p4jIfeXXFyXyOdkQfE4OC+L7QkQeFpH1wN0i0lVEPg62fZ2IjBaR5lHrXCwixweP7xaRV0TkuWD7Z4tITh2nzRaRb4Jx/xGRl6WKUoOIXCEic0TkJxF5T0Q6ldvHN4nIj8E2/K+IxAXj4kTkThFZEuzT50SkWdS8R4rIl8H7vkzsbC2ihVTwfyHm4WB5G0Vkloj0riz2PZKq+mBfo18AXA/0BwqA/aPGfYKd2keeXwZ8HvVcgV9EPR8IrAOygWTgn8DEYFwTYBlwOVZ6yg6m7RWMHwWsBwYE40cDLwXj0oBVwG1YQkoDDgnG3YsdaPYD0oEvgT8H404G1gC9g/W/GB0zMAJ4C2gZLPO/wF+DcccChcCDwbY0qmDfldkf5cZ9Cvw7iDcLyAUGBeMmARcHj1OBQ4PHvwliaAzEB+9J0wqWnQQsAW4BEoHBwXt3X2VxldvuUcBG4Ais0ZISvHZfuW2/N1j+qcDPQItg/EvB0BjoGbyvle2HzGDdCeX2WyFwY/BeNwJ+AZwQ7Ot0LMGPiJpnMXB88PhuYFsQVzzwV+Cr2k4btR9vDrbzHGBHZD9UsC1nYf8vPYK47wS+LLePJ2Cfp47ADwT/P8AVwbxdgvf8NeD5YFxHYDMwJIijFZBVg/+Lk4BpQHNAgrjaxjqn1Gt+inUAYRiAI7F/8NbB87nALVHjP6F2ifpp4G9Rz1OD5WcC5wOflVv/E8BdweNRwFNR404F5gaPhwDfVLINC4FTo56fBCwOHj8DPBA17sBIzMEHOx/oGjX+MGBR8PjY4J82pYr9V2Z/RL3eASgC0qJe+yswKng8Ebgnst+jprkCO9D0qeZ9OxpYCUjUa19Su0T9XLnxoyibqLdSNrmuBQ7Fkl0B0C1q3H0V7YdgXCYVJ+ql1WzjWdHvOTsn3w+jxvUEttZ22mA/rii3Hz+n8kT9LnBl1PM47ADWKWofnxw1/nrgo+DxR8D1UeO6BfsxAbgDeL2SdY6i8v+LgdjB4FAgrrr/9z1x8NKHuRR4X1XXBc9fpFz5o5baYS0UAFR1C5AHtAc6AYcEp3YbRGQDcCHQJmr+1VGPf8YSPVjiW1iTdQaP20WNW1ZuXEQ61iKcFhXP+OD1iFxV3VbJeqvSDlivqpvLrbt98PhK7KAxNygdnB68/jzwHvCSWKnmbyKSWMnyV2jw31rBttXEsmrG52nZi3+R9yMdSy7R81e3rGrXLyL7ichLIrJCRDYBLwCtq5i//GclRSqvdVc2bUX7sapt6QQ8EvV5WY8d8NtHTVP+8xb9WSz/OU0A9qfqz3dF8acCqOrHwL+AR4E1IvKkiDStYjl7nH0+UYvVYs8DjhGR1WJ12FuAviLSN5gsH0tmEW2o2krswxxZRxPsNG4F9gH+VFWbRw2pqnpdDcJdBnStZFyZdWKnkSuDx6uwf4LocRHrsFZjr6h4mqlqatQ0db3F4kqgpYiklVv3CgBVna+qQ7ByzYPAqyLSRFULVPUeVe0JHA6cjl1DKG8V0F5EpJJtK/O+iUhF71tdty0XK1tkRL3WoZJpq1pP+df/GrzWR1WbAhdhSbAhVbQfq9qWZcBvyn2GG6nql5XMH/1ZrOhzWoiV5qr6fFdJVf+hqv2BXtjB//d1WU5Y7fOJGju1LMJOBbOCoQfwGaXJYQZwjog0Di5EXVluGWuwmlvEi8DlIpIldkHvL8BkVV0MjAMOFJGLRSQxGA4WkR41iHUc0EZEhopdAEwTkUOCcWOAO0UkXURaA/+DtcYAXgEuE5GeItIYuCuyQFUtBv4PeFhE9gMQkfYiclIN4okmYhcBSwZVXYaVIv4avNYH23ejgxkuEpH0IIYNwXKKROQ4ETlIrBfGJuzUuKiCdU7C/slvEpEEETkHq2FGzAR6Be9DCnb6Xy9UtQirr94dfC66U/HBJCIXKKbs56QiacAW7KJje3ZPwpmE7d8bgv14JmX3Y3mPA3eISC8AEWkmIr8qN83vRaSFiHTAat8vB6+PAW4Rkc4ikor9b7wcnLWMBo4XkfOCOFqJSFZ1wQf/P4cEZ135WC2+os/LHssTtZU4RqrqUlVdHRmwU6kLg1PDh7E67RrgWYJEE+Vu4NngVPA8Vf0I+BMwFmutdAUuAAjKACcGz1dip3ORC3VVCuY9AfhlMN984Lhg9H3AVGAW8C0wPXgNVX0Xu2D4MXYh5+Nyi/5D8PpXwen2h1jtsDYOx1rmJUOw74Zg9dmVwOtYLf6DYJ6TgdkisgV4BLggKLG0AV7FkvQc7ILkC5SjqjuwC1+XAT9h9f/Xosb/gF0I/BDbV5X1yKirG4Bm2HvxPJaEKux/r6o/A/cDXwSfk0MrWeY92AXmjcDbRG1PQ4naj1diB8yLsEZBZdvyOvaZfSn4vHwHnFJusjexC3wzsO14Onj9GWxfTcT6lW/DLqaiqkux2vNtWDllBva9huo0xRobP2GllDzgoRrMt8eQsmUp51xdiciD2JelduX6RiiIyGTgcVWtVXfMYN59+gtgDcFb1M7VkVh/+D5BP94BWIv09VjHVRcicoyItAlKDpcCfbCLyi4E/JtQztVdGlbuaId12/s7dsq/J+qGXctIxXpeDFbVVbENyUV46cM550LOSx/OORdyDVL6aN26tWZmZjbEop1zbq80bdq0daqaXtG4BknUmZmZTJ06tSEW7ZxzeyURqfRbtTVK1CKyGLtZShFQqKo5Vc/hnHOuvtSmRX1c1L0wnHPO7SZ+MdE550Kupi1qBd4PvnH0hKo+WX4CEbkGuAagY8eO5Uc75/ZABQUFLF++nG3b6nLzRFeRlJQUMjIySEys6IaQFatpoj5CVVcGN+35QETmqurE6AmC5P0kQE5OjnfOdm4vsHz5ctLS0sjMzKTszfVcXagqeXl5LF++nM6dO9d4vhqVPlR1ZfB3LfYV2arurOWc20ts27aNVq1aeZKuJyJCq1atan2GUm2iFpEmkfsJB/dVPhG7W5Zzbh/gSbp+1WV/1qRFvT/wuYjMBL4G3lbVBrlZy5//DO+91xBLds65PVe1iVpVf1TVvsHQS1Xvb6hgHnwQ3n+/oZbunNvT5OXlkZWVRVZWFm3atKF9+/Ylz3fs2FGjZVx++eXMmzevymkeffRRRo8uf5v58AjV3fOSk2F7hbcqd87ti1q1asWMGTMAuPvuu0lNTeV3v/tdmWlKfgA2ruJ258iR1d9S+7e//e2uB9uAQtWPOikJaniQdM7twxYsWEDv3r259tpryc7OZtWqVVxzzTXk5OTQq1cv7r333pJpjzzySGbMmEFhYSHNmzdn2LBh9O3bl8MOO4y1a9cCcOeddzJixIiS6YcNG8aAAQPo1q0bX35pPwWZn5/PueeeS9++fRkyZAg5OTklB5GG5i1q51yNDB0K9Z2XsrIgyI+19v333zNy5Egef/xxAB544AFatmxJYWEhxx13HIMHD6Znz55l5tm4cSPHHHMMDzzwALfeeivPPPMMw4YN22nZqsrXX3/NW2+9xb333sv48eP55z//SZs2bRg7diwzZ84kOzu7boHXQaha1J6onXM11bVrVw4++OCS52PGjCE7O5vs7GzmzJnD999/v9M8jRo14pRT7Ocd+/fvz+LFiytc9jnnnLPTNJ9//jkXXHABAH379qVXr171uDVVC1WL2ksfzoVXXVu+DaVJkyYlj+fPn88jjzzC119/TfPmzbnooosq7KuclJRU8jg+Pp7CwsIKl52cnLzTNLH8kRVvUTvn9nibNm0iLS2Npk2bsmrVKt5rgH6+Rx55JK+88goA3377bYUt9oYSqha1J2rnXF1kZ2fTs2dPevfuTZcuXTjiiCPqfR033ngjl1xyCX369CE7O5vevXvTrFmzel9PRRrkNxNzcnK0Lj8cMHAgFBTAZ5/Ve0jOuTqYM2cOPXr0iHUYoVBYWEhhYSEpKSnMnz+fE088kfnz55OQUPv2bkX7VUSmVXav/1C1qJOSID8/1lE459zOtmzZwqBBgygsLERVeeKJJ+qUpOsiVInaSx/OubBq3rw506ZNi8m6/WKic86FnCdq55wLuVAlau9H7ZxzOwtVovYWtXPO7cwTtXMutI499tidvrwyYsQIrr/++krnSU1NBWDlypUMHjy40uVW14V4xIgR/PzzzyXPTz31VDZs2FDT0OuVJ2rnXGgNGTKEl156qcxrL730EkOGDKl23nbt2vHqq6/Wed3lE/U777xD8+bN67y8XRGqRB2pUcfwK/XOuRAZPHgw48aNY3vQglu8eDErV64kKyuLQYMGkZ2dzUEHHcSbb76507yLFy+md+/eAGzdupULLriAPn36cP7557N169aS6a677rqS26PeddddAPzjH/9g5cqVHHfccRx33HEAZGZmsm7dOgCGDx9O79696d27d8ntURcvXkyPHj24+uqr6dWrFyeeeGKZ9eyK0PWjBvt2YtS9U5xzYRCD+5y2atWKAQMGMH78eM4880xeeuklzj//fBo1asTrr79O06ZNWbduHYceeihnnHFGpb9H+Nhjj9G4cWNmzZrFrFmzytyi9P7776dly5YUFRUxaNAgZs2axU033cTw4cOZMGECrVu3LrOsadOmMXLkSCZPnoyqcsghh3DMMcfQokUL5s+fz5gxY/i///s/zjvvPMaOHctFF120y7spVC3qSKL28odzLiK6/BEpe6gqf/zjH+nTpw/HH388K1asYM2aNZUuY+LEiSUJs0+fPvTp06dk3CuvvEJ2djb9+vVj9uzZ1d5s6fPPP+fss8+mSZMmpKamcs455/BZcN+Lzp07k5WVBVR9G9XaCmWLevt2SEuLbSzOuXJidJ/Ts846i1tvvZXp06ezdetWsrOzGTVqFLm5uUybNo3ExEQyMzMrvK1ptIpa24sWLeKhhx5iypQptGjRgssuu6za5VR1f6TI7VHBbpFaX6WPULWoI+UO70vtnItITU3l2GOP5Yorrii5iLhx40b2228/EhMTmTBhAkuWLKlyGUcffXTJj9d+9913zJo1C7DbozZp0oRmzZqxZs0a3n333ZJ50tLS2Lx5c4XLeuONN/j555/Jz8/n9ddf56ijjqqvza1QaFvUzjkXMWTIEM4555ySEsiFF17IL3/5S3JycsjKyqJ79+5Vzn/ddddx+eWX06dPH7KyshgwYABgv9TSr18/evXqtdPtUa+55hpOOeUU2rZty4QJE0pez87O5rLLLitZxlVXXUW/fv3qrcxRkVDd5nTMGPj1r2HOHKhmvzvndgO/zWnDqO1tTkNZ+vAWtXPOlQpVoo6UPrxG7ZxzpUKZqL1F7Vx4xPJHXfdGddmfnqidc5VKSUkhLy/Pk3U9UVXy8vJISUmp1Xyh6vXh3fOcC5eMjAyWL19Obm5urEPZa6SkpJCRkVGreUKVqL1F7Vy4JCYm0rlz51iHsc/z0odzzoWcJ2rnnAu5UCVqr1E759zOQpWovUXtnHM7q3GiFpF4EflGRMY1VDCeqJ1zbme1aVHfDMxpqEDAE7VzzlWkRolaRDKA04CnGjIYr1E759zOatqiHgHcDhQ3YCzExUFCgreonXMuWrWJWkROB9aq6rRqprtGRKaKyNRd+RaT/xK5c86VVZMW9RHAGSKyGHgJGCgiL5SfSFWfVNUcVc1JT0+vc0CeqJ1zrqxqE7Wq3qGqGaqaCVwAfKyqu/6zupVISvIatXPORQtVP2rwFrVzzpVXq5syqeonwCcNEknAE7VzzpUVuhZ1UpInauecixa6RJ2c7DVq55yLFspE7S1q55wr5YnaOedCLnSJ2mvUzjlXVugStdeonXOurFAmam9RO+dcKU/UzjkXcqFL1P4VcuecKyt0idpb1M45V5YnauecCzlP1M45F3KhS9SRGrVqrCNxzrlwCF2ijvzAbUFBbONwzrmwCG2i9vKHc84ZT9TOORdyoUvUSUn21/tSO+ecCV2i9ha1c86V5YnaOedCLnSJOlL68ETtnHMmdIk60qL2GrVzzpnQJmpvUTvnnPFE7ZxzIRe6RO01auecKyt0idpr1M45V1ZoE7W3qJ1zzniids65kAtdovYatXPOlRW6RO01auecKyu0idpb1M45ZzxRO+dcyIUuUfttTp1zrqzQJeq4OEhI8Ba1c85FhC5Rg/8SuXPORas2UYtIioh8LSIzRWS2iNzT0EF5onbOuVIJNZhmOzBQVbeISCLwuYi8q6pfNVRQSUleo3bOuYhqE7WqKrAleJoYDNqQQXmL2jnnStWoRi0i8SIyA1gLfKCqkyuY5hoRmSoiU3Nzc3cpKE/UzjlXqkaJWlWLVDULyAAGiEjvCqZ5UlVzVDUnPT19l4JKSvJE7ZxzEbXq9aGqG4BPgJMbJJpAcrLXqJ1zLqImvT7SRaR58LgRcDwwtyGD8tKHc86Vqkmvj7bAsyISjyX2V1R1XEMG5YnaOedK1aTXxyyg326IpURSEmzZUv10zjm3LwjtNxO9Ru2ccya0idpLH845ZzxRO+dcyIUyUXs/auecKxXKRO01auecKxXaRO0tauecM56onXMu5EKZqCO3OdUGvUefc87tGUKZqCM/cFtQENs4nHMuDEKdqL384Zxznqidcy70Qpmok5Lsr3fRc865kCZqb1E751wpT9TOORdyoUzUkdKHJ2rnnAtpoo60qL1G7ZxzIU/U3qJ2zjlP1M45F3qhTNReo3bOuVKhTNReo3bOuVKhTtTeonbOOU/UzjkXeqFM1F6jds65UqFM1F6jds65UqFO1N6ids45T9TOORd6oUzUXqN2zrlSoUzUcXGQkOA1auecg5AmavBfInfOuQhP1M45F3KhTdRJSZ6onXMOQpyok5O9Ru2ccxDyRO0tauecq0GiFpEOIjJBROaIyGwRuXl3BOalD+ecMwk1mKYQuE1Vp4tIGjBNRD5Q1e8bMjAvfTjnnKm2Ra2qq1R1evB4MzAHaN/QgXnpwznnTK1q1CKSCfQDJlcw7hoRmSoiU3Nzc3c5ME/UzjlnapyoRSQVGAsMVdVN5cer6pOqmqOqOenp6bscmNeonXPO1ChRi0gilqRHq+prDRuS8Rq1c86ZmvT6EOBpYI6qDm/4kIyXPpxzztSkRX0EcDEwUERmBMOpDRyXJ2rnnAtU2z1PVT8HZDfEUobXqJ1zzoT6m4leo3bOuZAnam9RO+ecJ2rnnAu90CbqpCQrfajGOhLnnIut0CbqyA/cFhTENg7nnIu18CTqoiK49FIYPRrwXyJ3zrmI8CTq+Hh491349FPAE7VzzkWEJ1EDdO4MixYBVqMGT9TOORfaRB1pUXtfaufcvi58iXrpUigq8tKHc84FwpWoMzOtm8eKFV76cM65QLgSdefO9nfRIm9RO+dcIJyJevFir1E751wgXIm6Y0cQ8Ra1c85FCVeiTk6G9u1h0SKvUTvnXCBciRpKuuh56cM550zoE7W3qJ1z+7pwJuoVK0jGMrQnaufcvi6ciVqV1PVLAcjPj3E8zjkXY+FM1EDrzYtISYGFC2Mcj3POxVhoE3X80kUceCDMnRvjeJxzLsbCl6jbtYPERFi0iO7dPVE751z4EnV8vH3xZdEievSwm+lt2xbroJxzLnbCl6jByh+LF9O9OxQXw4IFsQ7IOediJ7yJOih9gJc/nHP7tvAm6txcDmy3BYA5c2Icj3POxVB4EzXQeO1iOnXyFrVzbt8W6kTtPT+cc24PSNQ9eliiLi6ObUjOORcr4UzU6enQuHFJi/rnn2HFilgH5ZxzsRHORC3iPT+ccy4QzkQN9kO3UYnae3445/ZV4U3UQYt6v3SleXNvUTvn9l3VJmoReUZE1orId7sjoBKdO8PmzciGn7znh3Nun1aTFvUo4OQGjmNnFfT8cM65fVG1iVpVJwLrd0MsZUUS9Y8/0r07rFoFGzfu9iiccy7m6q1GLSLXiMhUEZmam5u76wvs1g1atIAXXii5oDhv3q4v1jnn9jT1lqhV9UlVzVHVnPT09F1fYKNGMHQovPUWfZgJeM8P59y+Kby9PgBuugmaNqXjs/eRmOh1aufcvincibp5c7jxRuJeH8vJHWZ7onbO7ZNq0j1vDDAJ6CYiy0XkyoYPK8rQodC4Mb/fcb8naufcPqkmvT6GqGpbVU1U1QxVfXp3BFaidWu4/nqOWPEyMv8HCgp269qdcy7mwl36iLjtNooTk7m96C8sXBjrYJxzbvfaMxL1/vuz+de/4SJe4L8PeR8959y+RVS13heak5OjU6dOrd+Frl7Nlk49mVNwAO0XfU67Tol1W05xMXz2Gbz+OixeDOvW2bBhA+y/P3TpYl+26dkTLrkEkpLqdTOcc64iIjJNVXMqGrdntKgB2rQh/38f42D9mumD/1L7+b/7zi5MdugAxx4LTz4JixZBcjL07QtnnAGdOsH8+fD443D11fDLX8LmzfW+KXWmanFdfbU9djWzfLm9r87tqVS13of+/ftrQ5l8wIVaQLwue/Wrms/0/vuqKSmqycmqZ52lOmaM6ubNJaO/+EJ14EDVK69UHTtWdeOGYtWnn1aNj1ft31919eqql//hh6p33qk6cqTqZ5/Z9MXFddvAqjz1lKqlaNUHH6z/5e+tjj5atVWr6t9H52IImKqV5NQ9LlGvmvOTLpUOujLtANUtW6qf4d13LUH36bPTP2phoeo991g+bttWtVkz2yMJCaqDBqlO+tM4LW7USLVrV9UFCype/pQpqklJpQk0MrRtq/qrX6n+4x+q06errlqlum6d6saNqtu3137DFy5UTU1VPe441fPOU42LU/3449ovZ1+zbp3tK1A9++yGOYA6Vw/2qkStqvrEBR9rEaLrT7/YWrDTp6v+8INqXl7ZCd9+25JoVpb9w0ZZskT1qKNsD/z616obNqju2KH66aeqf/iDamamjbuw6yTdltpSi/fbT/Xrr8suPy9PtVMn1Y4dLRHPn6/6zjuqjzyieuGF9nr5BB4Zjj3WWuBRLftKFRaqHnGEatOmFvimTardu6vut5/q8uV124lLl6pefbXqMcfU7IC3p3ruOdvfF1xgf0ePjnVEzlVor0vU69erjkj6fcUJsFUr1cMPt0SZmGili6gEvmSJ6tChqk2aWAP12WcrbmQVFKg+/7xqjx6q3ZijyxIztahRY9X//tcmKCpSPfVUW8fkyZUHu2SJlVoee8xa1w89pHrHHdZKB9XGjVUvuUT1qypKOQ88YNM+/7yqWl6d89r3WpDcRJd1OlxnTNlR852Xm6t66612lpGYaMu9446az19fnnpK9fbb7SBUExs21G09552n2qaNHYUPPVS1ZUs7qDoXMntdolZV/cv9xdqfKfr0kPe1+LXXLYn9/e+q11xjrcQ2bax+8dNPqqr67bfWco6Pt+HCCyuvZkQrKlL9z39Ue7Zcpd8k9NfiuDjVxx9Xvf9+232PPlpm+p9+smWfdpqN+vHHssvbutUawUWFxaqff26t2rQ0W9aAAaovvKC6bZvqmjV2pjB6tCXUwYO1sKBYf/Wr0mPSebykCvps85t0R3W5es4c1ZtvtnXFxaledpnq4sWql15qy587t8b7fpdNm2b1JVC96KKqk3VBgepdd1nMd99du/Vs325nIVddZc/nzlVNSdHiM8/0EogLnb0yURcUWE4GyzmVJarCQtW//tXyQmqq6i23WCO3tubMUe3WfrOOjz/VViqiOmRImX/4pUtVe/WyvNelS2lCPfBA1d69rTEXeS093c7Gn3pKdensTar//KdNWNFZQkaGam6u3n67Pb3xRtVXXlGdMUN17ilDVUHfv+T5nYMuLrarowMH2oyJiXa0mj27dJrVq604f8IJuyd5bdtmO6ltW9U//tHiuvjiipP10qUl9akdHYMd+vbbNV/Xhx/aPG+8UfJS0d8eUgUddexIz9UuVPbKRK1qeeXuu20rTjll51LrkiXWuAa7rleuTF1ry5ap9u5eoP+Kv1FXdjtGNywvrS/PnKnarp014D780F774QfVESNUTz/dOptcf73qffdZTr74YstVkVx8/vmqc78vsouff/yjlUlee83KKps26Ysv2nTXXVduH2zfod80O0bzaaSbJn5TOmLrVmutgtXR//IXa6UHNmywiktGhuqUS/9p0/3nP3XfOVu2qA4fvvMpRHnDhpVNuH/+sz2/9FJL1uvW2ZnEU0+ptmihmpqqX1z7nKbws/7YtK8Wt2ihumhRzWIaOtRKPFEfjFFPF+oEjtHtJOp7N7xVp011riHstYk64okn7Mw4I8MS84E3ShAAABIxSURBVNlnWyu7WTNrRY8aVX+NxXXrrNQZaVQfdJB160tLU23f3hJ2TRUXW+P2jjusZh6pSCxcWHa66dNVGzVSPfLIijuMzHx/tS6jveY1y7QAV60qDfLPf96ptfrpp3adMz7erknGU6AL0rK0oG1GzS5uVrQhF15o60tKshp4+Qu7qqqTJtlGXnmlfvWVTXbttaqv9r1XFbQwoVzvmf79deqYHzQpSfUXv1DtwgLdnNBMi/r1twNRdTF17WrXEQL5+XYwPS57g85perBuI0kXP/5u7bfXuQaw1ydqVetscdZZ1mW2d2/7hxw4sGZ16Nravt1azffco3rSSdaK7t/fztTras0aK8skJ9u70q2blXZGjbKkmpFRdTfgu0/5SreRpFtzjlTt0MEuUr76aplptm2z63cilvi++spy+COPqA5q9IUq6IxBt9T+qPb44xb0bbepXnGFraB5c9V777Wzgi++sPpwt26qHTvqvCkbNS3Ncnp6uvWw+V2rZ/Tv3KJP9xmhW54bqzplii6cV6CtW6secIAdf558UvVM3rBSyOXXVB3T999bTP/+d8lL991nL02cqLp6znqdmdBPt0mybh33Ye22N6Kw0Fr3ubl1m9+5KPtEoo6loqL6W9ayZfZdltNOswMA2Hd1pkypfr7rE5/Ukpr29Ollxk+apNqzp43+zW92LhMtXao6LuM3qqBLj7zA+nvXxNSplnFPOaV0R8yapXryyWVbx8GQ/9aH2qOHauvWZQ9sxcXWISY+3hLzxInW2m/Z0kpIEc89p/pXrHyy/cprK29ZP/igrTNYyerVdnZ19tmlk3z0cq7O5CDdHt9I9b33qt7O7dutK+i991or/cADS3vNNI7qDRRWq1db7W3GjFhH4irhiXoPVVho+fbbb2s2/Z13qp7MO/q3363Rjz+2KkZ+vrXURayh/c47lc+/Lb9Q/51xnxYSp9s7drUkXJX166053KFDxRcAVq2yDXj3XdVRo7T4w4/03HOt+vHRRxUvcuLE0tp9YqLqJ5/sPM0rYwr1IfmdKmhRVvbOtSJVuwiZlVXy9Lrr7ILyvHllJ7v3hjU6k4O0SOLsSFH+bOL991VPPNFqT5F6V+/equeeq0W//4O+c9YTuqhV0Bvosceq3l+xkp9vPYoiR/2nnvJeLyHkiXofsXmz6mGHlTZg4+KsAhG5CFmTRvLSpaqnN/9MVyZkaHFiojW///EP1fHjLSHOnav6wQf2ZZ2BAy2bfvWVrl2resMNquecY70ic3KsHDRsmJVYiopU//Y3i+Vvf6s6hlWrrOT9yiuVT/Pii6pn8KZuSmiuxc2aWV/1/HwbGfk24p13qqpVQeLjLb7yduxQPemIzTpWztWSbz/l59vRMXJW0LGj6k03qb7+ekntfdEi+w4SqDZhs369/2n2ZNiw0jOLggKLpaZ9xRtCUZG9KSKWoI8/Xksu3kb2lwsFT9T7mHXrrOV8112WdypqlVZlwgTV9Lh1+lnG+Voc6eNd0RAfr/rEE5qbaxdVk5Ks593hh1sl5JhjbBKwawZxcaqDB9dfY27kSNVOLNJ5zQ8uPTL17m3f+gTVyZN14UJrWDdtqrp2bcXLyctT7dG9WO9Jvl+LRSwxR45yDz1kxf0oL75oy0tLs27vjz5qF2Q//MVvSjc2coQEuyDw4ov1WyOrqdtusxiGD9cff1TN31So+j//U3pmUNdvtrp654na1drw4fbpuP66Yl03e7XVJJ5+2jLTp59a63rrVl23zm6jkpJS2i0xWl6effvzrLOsq/amTfUb57//rZrIdr1vwJuae92frH68//6qPXvq2P8UabNm1vtn3Liql7NkiZVcLmr1jhZ06mJfDipXztm2zb6fBHbmEl1x+ctfVKFYRx/1mBZfeKF1dr/rLtX//V87ioH9feMN+1ZUQUH97ojytm+3vqGg+tvf6shnikuOrQcdpPrQCeN1e0qaFv/iF3aBw8WcJ2pXa8XFdu0pcq1s6NCd/5/z8qy1mpxc/bW4hvTww6X3XcrOVv37Q8V6w28tMR18cPVduyNmzLBW8kEHlb2AqWoloUiZd9iwivPsH/5g4886y7qMzpoVVD2Kiqw0c8ABZc9IUlKs20uXLqp9+1r/y9NOsz6at99u37QdO7b6LpPFxVaSevJJO5JkZ5de6DztNJ0yqUCTk61H1J/+ZGc76emqhzBJ8xOaanGXrrvWZcnVi6oS9Z7zwwEuJr7/Hh58EEaPhrg4OOAAaNTIhhUrbHjzTTj55NjGuWoVvPyyxRn56A0darHX5rcfPvwQTj8dtm+Hww+HSy+F9u3h8sth61Z47jk4++yK51WFO++0W52vW2evpaXB0UfDaafBqScW0mnGm7B0qd3nvKJh40bIzYW1a2HHDltISgqceir86leQnW0bu2yZDdOnw8SJNj1AixbQv79N178/aw87k5wjkomLs/3SunVprA8/DC/fNpmP40+kUYfWxH06ATp2rP3Od/Wiqh8O8ETtamTJEvjXv+xHcX7+2ZJWURHccUfsk3R5P/xgMWZl1W3+lSvhhRfg2WftQAXQrZv9KFCPHtXPrwoLF8KkSfDll/D++/DjjzauZ0847DD7rYq+faFPH2jevJKFbNwIM2fCq6/asHr1ztN17AjHHGNHg6OPtiOpCAAFBXDCCTB5MnzxheXu8p57Dh67/GvelxNp0iyBuEED4Ygj7CiVlQWJdfwlJVdrnqidqwNVa4VOmwa//jU0bVr35fzwA7zzDowfb8vLyysdn5oKbdtCmzbQrp3l3k6dbOjc2XJvUnyRZdtFiyAjo3Ro0qTMurZvtwPN8uV2oHn6aUvGF19ceXzjxsG9587kT0kPckLql6SsXmIj9t8ffv97uPbandZTZzt2wFtv2ZlAerqto00ba+qnpdlObtq08gPEzz/bGcWWLdZa2LrVjkitWtmy9tvPTv3mzIEZM+Cbb+wA16qVraN1azvaHnVU6A5CnqidCxFVyzUzZ9ovxK1YYblk1SpLskuXllY9ABISLFn36gW9e8NBB9nQpYvlq48+sgPABx/YGU+0W26B4cOrj+nLL+1gtHQp/Ony5dxx9BekvPCU1YJat4bbbrOfsFu9unTYuhUKC+3UCqzJftJJljDLb/DcuXbUePZZqwuJ2OuVadQIWra0Uk7z5rBpkx191q+vfmMSEiwusLJR27bw00/2u6gRLVvCmWfCOefA8cfbdLW1YYNtS9u29XIg80Tt3B6kuBjWrLFy08KFMHt26fDjj6X5rVEjS+hFRdYIHTQI+vWzmnpGhrXMu3UrqYRUa/NmK2U9+qi15P/1Lzil2ZfIfX+2I0E0Efu90fh4G4qKID/fxmVnW4t13Tr7rcoffrCklpBgyfGqqyw5bt5sCX/NGjvF2LzZEvKmTTb9Tz+VDmlppWcR7drZBkculiQk2PyRZW3dake0fv3gwANtPFjyzsuzmtTYsfDf/1p5KSXFyj0DB9pO7NoVmjUrbXGvX29H1ZkzYdYs254ffrBrCREtWlhsBxxgy64DT9TO7SXy861u/u23NjRpYo3YQw+tvzP5iRPhyithwQLo3h2uvx4u7zeD1A3LrfXYtq2VGCIJEOzoMnOmJfTx4+Grr6ykccABlix79YLBg3dubWO5sqjIGrm1kZ9vZxGTJlmO7N7dhoyMyg9Oa9faNdi4OIgv2kHa1AlkzH6PxIkfWRKO1qSJHQgiV4bBtrt7d9umAw+08s3q1dbaX77cpnnjjdptSMATtXOuVrZvh1desdb15MlWRz/9dLvGGLkYmphojdRIVSEhARo3DoZGSnzCztmyuBjeftvK1PPmWcN0zRobFykfd+9u1Y7t2+2MYccOa/Q2a1ba0J0wwaoy27aVNugj0tLg4IPhkENsSE21hP7++1ayLq91a7j1VrjhvLWkfTPRalAbNtiwZYu1sLOybKMrONBEb9vq1dbgrwtP1M65OpsyBR57DN57z2roYIkzKcmqFBVJSLDqxxln2LD//laeHjHCqiEtWlgPmG7dSqsT8+bZNcC5cy0/JifbOpKSLCFv3Fhaes7MtCrKGWfYevLybL65c61hPHmy/Y1Mn5Bg1Y0TT7TGPVhi3bYNnn8e3n3XYrr5ZusJ2bGjNZ4rapkXFVlCXrbMzjqmTbPhm2/sALNsWd32sydq59wuU7UkNGkSfP11abmiZUtLUEVF1ikjP99ayePH28VSsMS+bZu1dG+7Dc49t2zlpKbr37rVlt+6dfW1961brXPJpk1w5JHW0q7M1Klw//1lqxbJyVbvT0y0bSsutlb+6tVlW/ApKdbg7t/fhssuq/l1gWieqJ1zMfHjj3bNbu5cuOgiK53UJYntLgsX2jWAJUusB8zy5Zag4+JsSEy00kaHDjZkZtpZQW0POhXxRO2ccyFXVaKO293BOOecqx1P1M45F3KeqJ1zLuRqlKhF5GQRmSciC0RkWEMH5ZxzrlS1iVpE4oFHgVOAnsAQEenZ0IE555wzNWlRDwAWqOqPqroDeAk4s2HDcs45F1GTRN0eiP6uzfLgtTJE5BoRmSoiU3Ojb1binHNul9QkUVfUPX2nzteq+qSq5qhqTnp6+q5H5pxzDoCafJ9mOdAh6nkGsLKqGaZNm7ZORJbUMabWwLpqp9r9whoXhDe2sMYF4Y0trHFBeGMLa1xQu9g6VTai2m8mikgC8AMwCFgBTAF+raqza7jyWhGRqZV9OyeWwhoXhDe2sMYF4Y0trHFBeGMLa1xQf7FV26JW1UIRuQF4D4gHnmmoJO2cc25nNbqViKq+A7zTwLE455yrQBi/mfhkrAOoRFjjgvDGFta4ILyxhTUuCG9sYY0L6im2Brl7nnPOufoTxha1c865KJ6onXMu5EKTqMN04ycReUZE1orId1GvtRSRD0RkfvC3RQzi6iAiE0RkjojMFpGbQxRbioh8LSIzg9juCV7vLCKTg9heFpGk3R1bEEe8iHwjIuNCFtdiEflWRGaIyNTgtTC8n81F5FURmRt83g4LSVzdgn0VGTaJyNCQxHZL8Nn/TkTGBP8T9fI5C0WiDuGNn0YBJ5d7bRjwkaoeAHwUPN/dCoHbVLUHcCjw22A/hSG27cBAVe0LZAEni8ihwIPAw0FsPwFXxiA2gJuBOVHPwxIXwHGqmhXV3zYM7+cjwHhV7Q70xfZdzONS1XnBvsoC+gM/A6/HOjYRaQ/cBOSoam+sK/MF1NfnTFVjPgCHAe9FPb8DuCPGMWUC30U9nwe0DR63BeaFYL+9CZwQttiAxsB04BDsW1kJFb3PuzGeDOyfdyAwDrstQszjCta9GGhd7rWYvp9AU2ARQWeDsMRVQZwnAl+EITZK74nUEuv2PA44qb4+Z6FoUVPDGz/F2P6qugog+LtfLIMRkUygHzCZkMQWlBdmAGuBD4CFwAZVLQwmidX7OgK4HSgOnrcKSVxg9815X0Smicg1wWuxfj+7ALnAyKBc9JSINAlBXOVdAIwJHsc0NlVdATwELAVWARuBadTT5ywsibpGN35yRkRSgbHAUFXdFOt4IlS1SO2UNAO7PW6PiibbnTGJyOnAWlWdFv1yBZPG6vN2hKpmY2W/34rI0TGKI1oCkA08pqr9gHxiU36pVFDrPQP4T6xjAQhq4mcCnYF2QBPsPS2vTp+zsCTqWt/4KQbWiEhbgODv2lgEISKJWJIeraqvhSm2CFXdAHyC1dGbB/eLgdi8r0cAZ4jIYuxe6gOxFnas4wJAVVcGf9ditdYBxP79XA4sV9XJwfNXscQd67iinQJMV9U1wfNYx3Y8sEhVc1W1AHgNOJx6+pyFJVFPAQ4IrpAmYac0b8U4pvLeAi4NHl+K1Yd3KxER4GlgjqoOD1ls6SLSPHjcCPvgzgEmAINjFZuq3qGqGaqaiX2uPlbVC2MdF4CINBGRtMhjrOb6HTF+P1V1NbBMRLoFLw0Cvo91XOUMobTsAbGPbSlwqIg0Dv5PI/usfj5nsbwYUK4Yfyp2l76FwP+LcSxjsDpTAda6uBKra34EzA/+toxBXEdip06zgBnBcGpIYusDfBPE9h3wP8HrXYCvgQXYaWpyDN/XY4FxYYkriGFmMMyOfO5D8n5mAVOD9/MNoEUY4gpiawzkAc2iXot5bMA9wNzg8/88kFxfnzP/CrlzzoVcWEofzjnnKuGJ2jnnQs4TtXPOhZwnauecCzlP1M45F3KeqJ1zLuQ8UTvnXMj9f21HBe6F9XoyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22782844188031642\n"
     ]
    }
   ],
   "source": [
    "## TRAINING\n",
    "# Fit the training data into the autoencoder.\n",
    "history = autoencoder.fit(X_train_swapped,X_train_norm,\n",
    "                          validation_data=(X_test_norm,X_test_norm),\n",
    "                          epochs=60,\n",
    "                          verbose=1,\n",
    "                          callbacks=[])\n",
    "# Plot training vs validation losses\n",
    "plt.plot(history.history[\"loss\"], c = 'b', label = \"Training\")\n",
    "plt.plot(history.history[\"val_loss\"], c = 'r', label = \"Validation\")\n",
    "plt.title(\"Autoencoder Loss during training epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(history.history[\"loss\"][-1])\n",
    "\n",
    "# Encode datasets using the trained encoder.\n",
    "X_train_encoded = encoder.predict(X_train_norm)\n",
    "X_test_encoded = encoder.predict(X_test_norm)\n",
    "\n",
    "# Renormalize data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_encoded = pd.DataFrame(scaler.fit_transform(X_train_encoded))\n",
    "X_test_encoded = pd.DataFrame(scaler.fit_transform(X_test_encoded))\n",
    "\n",
    "# Next we will use this datasets to evaluate and compare with the latent representation obtained with the autoencoder:\n",
    "# Original dataset: \"X_train_norm\" a 433x20502 Matrix.\n",
    "# Encoded dataset: \"X_train_encoded\" a 433x{encoded_dim} Matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 389 samples, validate on 44 samples\n",
      "Epoch 1/200\n",
      "389/389 [==============================] - 2s 5ms/sample - loss: 2.8768 - accuracy: 0.5219 - val_loss: 2.4990 - val_accuracy: 0.6591\n",
      "Epoch 2/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 2.6361 - accuracy: 0.5450 - val_loss: 2.3450 - val_accuracy: 0.6591\n",
      "Epoch 3/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 2.4824 - accuracy: 0.5553 - val_loss: 2.2587 - val_accuracy: 0.6591\n",
      "Epoch 4/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 2.4052 - accuracy: 0.5758 - val_loss: 2.1980 - val_accuracy: 0.6591\n",
      "Epoch 5/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 2.3113 - accuracy: 0.5707 - val_loss: 2.1397 - val_accuracy: 0.6591\n",
      "Epoch 6/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 2.2537 - accuracy: 0.5758 - val_loss: 2.0922 - val_accuracy: 0.6591\n",
      "Epoch 7/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 2.1868 - accuracy: 0.5861 - val_loss: 2.0491 - val_accuracy: 0.6591\n",
      "Epoch 8/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 2.0994 - accuracy: 0.6350 - val_loss: 2.0078 - val_accuracy: 0.6591\n",
      "Epoch 9/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 2.0457 - accuracy: 0.6735 - val_loss: 1.9657 - val_accuracy: 0.6591\n",
      "Epoch 10/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 2.0044 - accuracy: 0.6581 - val_loss: 1.9260 - val_accuracy: 0.6591\n",
      "Epoch 11/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.9834 - accuracy: 0.6915 - val_loss: 1.8928 - val_accuracy: 0.6591\n",
      "Epoch 12/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.9316 - accuracy: 0.6864 - val_loss: 1.8653 - val_accuracy: 0.6591\n",
      "Epoch 13/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.8653 - accuracy: 0.6838 - val_loss: 1.8344 - val_accuracy: 0.6591\n",
      "Epoch 14/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.8476 - accuracy: 0.6761 - val_loss: 1.8046 - val_accuracy: 0.6591\n",
      "Epoch 15/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.7796 - accuracy: 0.7095 - val_loss: 1.7793 - val_accuracy: 0.6591\n",
      "Epoch 16/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.7862 - accuracy: 0.6889 - val_loss: 1.7635 - val_accuracy: 0.6591\n",
      "Epoch 17/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.8137 - accuracy: 0.6889 - val_loss: 1.7373 - val_accuracy: 0.6591\n",
      "Epoch 18/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.7438 - accuracy: 0.6915 - val_loss: 1.7126 - val_accuracy: 0.6591\n",
      "Epoch 19/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.7208 - accuracy: 0.6864 - val_loss: 1.6978 - val_accuracy: 0.6591\n",
      "Epoch 20/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.6611 - accuracy: 0.7301 - val_loss: 1.6856 - val_accuracy: 0.6591\n",
      "Epoch 21/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.7159 - accuracy: 0.6941 - val_loss: 1.6627 - val_accuracy: 0.6591\n",
      "Epoch 22/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.6869 - accuracy: 0.6967 - val_loss: 1.6381 - val_accuracy: 0.6591\n",
      "Epoch 23/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.5780 - accuracy: 0.7429 - val_loss: 1.6137 - val_accuracy: 0.6591\n",
      "Epoch 24/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.5961 - accuracy: 0.7095 - val_loss: 1.5900 - val_accuracy: 0.6591\n",
      "Epoch 25/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.6087 - accuracy: 0.7147 - val_loss: 1.5758 - val_accuracy: 0.6591\n",
      "Epoch 26/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.5867 - accuracy: 0.7121 - val_loss: 1.5573 - val_accuracy: 0.6591\n",
      "Epoch 27/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.5668 - accuracy: 0.7018 - val_loss: 1.5380 - val_accuracy: 0.6591\n",
      "Epoch 28/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.5029 - accuracy: 0.7224 - val_loss: 1.5170 - val_accuracy: 0.6591\n",
      "Epoch 29/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.4609 - accuracy: 0.7249 - val_loss: 1.4975 - val_accuracy: 0.6591\n",
      "Epoch 30/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.4608 - accuracy: 0.7198 - val_loss: 1.4782 - val_accuracy: 0.6591\n",
      "Epoch 31/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.4446 - accuracy: 0.7224 - val_loss: 1.4611 - val_accuracy: 0.6591\n",
      "Epoch 32/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.4254 - accuracy: 0.7198 - val_loss: 1.4445 - val_accuracy: 0.6591\n",
      "Epoch 33/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.4248 - accuracy: 0.7249 - val_loss: 1.4284 - val_accuracy: 0.6591\n",
      "Epoch 34/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.4137 - accuracy: 0.7121 - val_loss: 1.4192 - val_accuracy: 0.6591\n",
      "Epoch 35/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.3665 - accuracy: 0.7275 - val_loss: 1.4057 - val_accuracy: 0.6591\n",
      "Epoch 36/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.3794 - accuracy: 0.7249 - val_loss: 1.3868 - val_accuracy: 0.6591\n",
      "Epoch 37/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.3631 - accuracy: 0.7249 - val_loss: 1.3691 - val_accuracy: 0.6591\n",
      "Epoch 38/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.3391 - accuracy: 0.7326 - val_loss: 1.3544 - val_accuracy: 0.6591\n",
      "Epoch 39/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.3410 - accuracy: 0.7275 - val_loss: 1.3397 - val_accuracy: 0.6591\n",
      "Epoch 40/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.2818 - accuracy: 0.7069 - val_loss: 1.3256 - val_accuracy: 0.6591\n",
      "Epoch 41/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.2939 - accuracy: 0.7275 - val_loss: 1.3118 - val_accuracy: 0.6591\n",
      "Epoch 42/200\n",
      "389/389 [==============================] - 1s 1ms/sample - loss: 1.2373 - accuracy: 0.7326 - val_loss: 1.2969 - val_accuracy: 0.6591\n",
      "Epoch 43/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.2500 - accuracy: 0.7198 - val_loss: 1.2832 - val_accuracy: 0.6591\n",
      "Epoch 44/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.2269 - accuracy: 0.7326 - val_loss: 1.2683 - val_accuracy: 0.6591\n",
      "Epoch 45/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.2230 - accuracy: 0.7404 - val_loss: 1.2548 - val_accuracy: 0.6591\n",
      "Epoch 46/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.2149 - accuracy: 0.7301 - val_loss: 1.2454 - val_accuracy: 0.6591\n",
      "Epoch 47/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.1752 - accuracy: 0.7275 - val_loss: 1.2479 - val_accuracy: 0.6591\n",
      "Epoch 48/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.1843 - accuracy: 0.7224 - val_loss: 1.2404 - val_accuracy: 0.6591\n",
      "Epoch 49/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.1856 - accuracy: 0.7172 - val_loss: 1.2296 - val_accuracy: 0.6591\n",
      "Epoch 50/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.1809 - accuracy: 0.7147 - val_loss: 1.2187 - val_accuracy: 0.6591\n",
      "Epoch 51/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.1581 - accuracy: 0.7275 - val_loss: 1.2095 - val_accuracy: 0.6591\n",
      "Epoch 52/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.1438 - accuracy: 0.7224 - val_loss: 1.1985 - val_accuracy: 0.6591\n",
      "Epoch 53/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.1220 - accuracy: 0.7326 - val_loss: 1.1921 - val_accuracy: 0.6591\n",
      "Epoch 54/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.1054 - accuracy: 0.7404 - val_loss: 1.1868 - val_accuracy: 0.6591\n",
      "Epoch 55/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.1138 - accuracy: 0.7352 - val_loss: 1.1786 - val_accuracy: 0.6591\n",
      "Epoch 56/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.0974 - accuracy: 0.7352 - val_loss: 1.1673 - val_accuracy: 0.6591\n",
      "Epoch 57/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.0917 - accuracy: 0.7404 - val_loss: 1.1596 - val_accuracy: 0.6591\n",
      "Epoch 58/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.0849 - accuracy: 0.7326 - val_loss: 1.1542 - val_accuracy: 0.6591\n",
      "Epoch 59/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.0872 - accuracy: 0.7301 - val_loss: 1.1466 - val_accuracy: 0.6591\n",
      "Epoch 60/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.0569 - accuracy: 0.7429 - val_loss: 1.1441 - val_accuracy: 0.6591\n",
      "Epoch 61/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.0482 - accuracy: 0.7455 - val_loss: 1.1423 - val_accuracy: 0.6591\n",
      "Epoch 62/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.0470 - accuracy: 0.7481 - val_loss: 1.1364 - val_accuracy: 0.6591\n",
      "Epoch 63/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.0377 - accuracy: 0.7404 - val_loss: 1.1304 - val_accuracy: 0.6591\n",
      "Epoch 64/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.0285 - accuracy: 0.7404 - val_loss: 1.1167 - val_accuracy: 0.6591\n",
      "Epoch 65/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.0268 - accuracy: 0.7455 - val_loss: 1.1219 - val_accuracy: 0.6591\n",
      "Epoch 66/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.0316 - accuracy: 0.7429 - val_loss: 1.1118 - val_accuracy: 0.6591\n",
      "Epoch 67/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.0133 - accuracy: 0.7352 - val_loss: 1.1016 - val_accuracy: 0.6591\n",
      "Epoch 68/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.0168 - accuracy: 0.7275 - val_loss: 1.0914 - val_accuracy: 0.6591\n",
      "Epoch 69/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 1.0064 - accuracy: 0.7352 - val_loss: 1.0844 - val_accuracy: 0.6591\n",
      "Epoch 70/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.9884 - accuracy: 0.7378 - val_loss: 1.0780 - val_accuracy: 0.6591\n",
      "Epoch 71/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.9886 - accuracy: 0.7352 - val_loss: 1.0753 - val_accuracy: 0.6591\n",
      "Epoch 72/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.9851 - accuracy: 0.7378 - val_loss: 1.0705 - val_accuracy: 0.6591\n",
      "Epoch 73/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.9717 - accuracy: 0.7352 - val_loss: 1.0635 - val_accuracy: 0.6591\n",
      "Epoch 74/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.9667 - accuracy: 0.7404 - val_loss: 1.0558 - val_accuracy: 0.6591\n",
      "Epoch 75/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.9660 - accuracy: 0.7352 - val_loss: 1.0538 - val_accuracy: 0.6591\n",
      "Epoch 76/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.9633 - accuracy: 0.7404 - val_loss: 1.0513 - val_accuracy: 0.6591\n",
      "Epoch 77/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.9559 - accuracy: 0.7352 - val_loss: 1.0419 - val_accuracy: 0.6591\n",
      "Epoch 78/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.9570 - accuracy: 0.7326 - val_loss: 1.0363 - val_accuracy: 0.6591\n",
      "Epoch 79/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.9434 - accuracy: 0.7352 - val_loss: 1.0354 - val_accuracy: 0.6591\n",
      "Epoch 80/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.9712 - accuracy: 0.7378 - val_loss: 1.0345 - val_accuracy: 0.6591\n",
      "Epoch 81/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.9399 - accuracy: 0.7429 - val_loss: 1.0341 - val_accuracy: 0.6591\n",
      "Epoch 82/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.9454 - accuracy: 0.7429 - val_loss: 1.0303 - val_accuracy: 0.6591\n",
      "Epoch 83/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.9518 - accuracy: 0.7404 - val_loss: 1.0265 - val_accuracy: 0.6591\n",
      "Epoch 84/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.9294 - accuracy: 0.7404 - val_loss: 1.0206 - val_accuracy: 0.6591\n",
      "Epoch 85/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.9283 - accuracy: 0.7404 - val_loss: 1.0101 - val_accuracy: 0.6591\n",
      "Epoch 86/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.9064 - accuracy: 0.7404 - val_loss: 1.0004 - val_accuracy: 0.6591\n",
      "Epoch 87/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.9046 - accuracy: 0.7429 - val_loss: 0.9971 - val_accuracy: 0.6591\n",
      "Epoch 88/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8968 - accuracy: 0.7429 - val_loss: 1.0037 - val_accuracy: 0.6591\n",
      "Epoch 89/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.9042 - accuracy: 0.7455 - val_loss: 0.9990 - val_accuracy: 0.6591\n",
      "Epoch 90/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.9053 - accuracy: 0.7404 - val_loss: 0.9937 - val_accuracy: 0.6591\n",
      "Epoch 91/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8943 - accuracy: 0.7455 - val_loss: 0.9905 - val_accuracy: 0.6591\n",
      "Epoch 92/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8998 - accuracy: 0.7429 - val_loss: 0.9852 - val_accuracy: 0.6591\n",
      "Epoch 93/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8993 - accuracy: 0.7455 - val_loss: 0.9816 - val_accuracy: 0.6591\n",
      "Epoch 94/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8840 - accuracy: 0.7455 - val_loss: 0.9804 - val_accuracy: 0.6591\n",
      "Epoch 95/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8944 - accuracy: 0.7378 - val_loss: 0.9772 - val_accuracy: 0.6591\n",
      "Epoch 96/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8820 - accuracy: 0.7429 - val_loss: 0.9885 - val_accuracy: 0.6591\n",
      "Epoch 97/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8852 - accuracy: 0.7455 - val_loss: 0.9920 - val_accuracy: 0.6591\n",
      "Epoch 98/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8803 - accuracy: 0.7404 - val_loss: 0.9878 - val_accuracy: 0.6591\n",
      "Epoch 99/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8935 - accuracy: 0.7429 - val_loss: 0.9874 - val_accuracy: 0.6591\n",
      "Epoch 100/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8792 - accuracy: 0.7429 - val_loss: 0.9826 - val_accuracy: 0.6591\n",
      "Epoch 101/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8851 - accuracy: 0.7455 - val_loss: 0.9772 - val_accuracy: 0.6591\n",
      "Epoch 102/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8670 - accuracy: 0.7404 - val_loss: 0.9718 - val_accuracy: 0.6591\n",
      "Epoch 103/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8687 - accuracy: 0.7429 - val_loss: 0.9746 - val_accuracy: 0.6591\n",
      "Epoch 104/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8655 - accuracy: 0.7429 - val_loss: 0.9697 - val_accuracy: 0.6591\n",
      "Epoch 105/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8728 - accuracy: 0.7429 - val_loss: 0.9660 - val_accuracy: 0.6591\n",
      "Epoch 106/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8668 - accuracy: 0.7404 - val_loss: 0.9635 - val_accuracy: 0.6591\n",
      "Epoch 107/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8665 - accuracy: 0.7429 - val_loss: 0.9575 - val_accuracy: 0.6591\n",
      "Epoch 108/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8513 - accuracy: 0.7404 - val_loss: 0.9525 - val_accuracy: 0.6591\n",
      "Epoch 109/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8528 - accuracy: 0.7455 - val_loss: 0.9519 - val_accuracy: 0.6591\n",
      "Epoch 110/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8451 - accuracy: 0.7429 - val_loss: 0.9498 - val_accuracy: 0.6591\n",
      "Epoch 111/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8484 - accuracy: 0.7455 - val_loss: 0.9437 - val_accuracy: 0.6591\n",
      "Epoch 112/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8461 - accuracy: 0.7429 - val_loss: 0.9553 - val_accuracy: 0.6591\n",
      "Epoch 113/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8594 - accuracy: 0.7429 - val_loss: 0.9539 - val_accuracy: 0.6591\n",
      "Epoch 114/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8636 - accuracy: 0.7429 - val_loss: 0.9464 - val_accuracy: 0.6591\n",
      "Epoch 115/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8643 - accuracy: 0.7404 - val_loss: 0.9449 - val_accuracy: 0.6591\n",
      "Epoch 116/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8457 - accuracy: 0.7429 - val_loss: 0.9432 - val_accuracy: 0.6591\n",
      "Epoch 117/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8477 - accuracy: 0.7429 - val_loss: 0.9408 - val_accuracy: 0.6591\n",
      "Epoch 118/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8504 - accuracy: 0.7429 - val_loss: 0.9409 - val_accuracy: 0.6591\n",
      "Epoch 119/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8445 - accuracy: 0.7404 - val_loss: 0.9419 - val_accuracy: 0.6591\n",
      "Epoch 120/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8494 - accuracy: 0.7429 - val_loss: 0.9431 - val_accuracy: 0.6591\n",
      "Epoch 121/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8542 - accuracy: 0.7429 - val_loss: 0.9403 - val_accuracy: 0.6591\n",
      "Epoch 122/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8442 - accuracy: 0.7429 - val_loss: 0.9399 - val_accuracy: 0.6591\n",
      "Epoch 123/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8533 - accuracy: 0.7429 - val_loss: 0.9368 - val_accuracy: 0.6591\n",
      "Epoch 124/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8369 - accuracy: 0.7429 - val_loss: 0.9347 - val_accuracy: 0.6591\n",
      "Epoch 125/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8348 - accuracy: 0.7429 - val_loss: 0.9339 - val_accuracy: 0.6591\n",
      "Epoch 126/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8346 - accuracy: 0.7455 - val_loss: 0.9313 - val_accuracy: 0.6591\n",
      "Epoch 127/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8371 - accuracy: 0.7429 - val_loss: 0.9292 - val_accuracy: 0.6591\n",
      "Epoch 128/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8325 - accuracy: 0.7429 - val_loss: 0.9295 - val_accuracy: 0.6591\n",
      "Epoch 129/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8335 - accuracy: 0.7429 - val_loss: 0.9273 - val_accuracy: 0.6591\n",
      "Epoch 130/200\n",
      "389/389 [==============================] - 1s 1ms/sample - loss: 0.8271 - accuracy: 0.7404 - val_loss: 0.9227 - val_accuracy: 0.6591\n",
      "Epoch 131/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8289 - accuracy: 0.7429 - val_loss: 0.9164 - val_accuracy: 0.6591\n",
      "Epoch 132/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8208 - accuracy: 0.7429 - val_loss: 0.9103 - val_accuracy: 0.6591\n",
      "Epoch 133/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8204 - accuracy: 0.7429 - val_loss: 0.9034 - val_accuracy: 0.6591\n",
      "Epoch 134/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8183 - accuracy: 0.7429 - val_loss: 0.9000 - val_accuracy: 0.6591\n",
      "Epoch 135/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8101 - accuracy: 0.7429 - val_loss: 0.8987 - val_accuracy: 0.6591\n",
      "Epoch 136/200\n",
      "389/389 [==============================] - 1s 1ms/sample - loss: 0.8008 - accuracy: 0.7429 - val_loss: 0.8980 - val_accuracy: 0.6591\n",
      "Epoch 137/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8082 - accuracy: 0.7429 - val_loss: 0.8952 - val_accuracy: 0.6591\n",
      "Epoch 138/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7963 - accuracy: 0.7429 - val_loss: 0.8931 - val_accuracy: 0.6591\n",
      "Epoch 139/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8058 - accuracy: 0.7429 - val_loss: 0.8969 - val_accuracy: 0.6591\n",
      "Epoch 140/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8179 - accuracy: 0.7429 - val_loss: 0.9015 - val_accuracy: 0.6591\n",
      "Epoch 141/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8119 - accuracy: 0.7429 - val_loss: 0.9002 - val_accuracy: 0.6591\n",
      "Epoch 142/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8084 - accuracy: 0.7429 - val_loss: 0.8993 - val_accuracy: 0.6591\n",
      "Epoch 143/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8102 - accuracy: 0.7429 - val_loss: 0.8966 - val_accuracy: 0.6591\n",
      "Epoch 144/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8049 - accuracy: 0.7429 - val_loss: 0.9007 - val_accuracy: 0.6591\n",
      "Epoch 145/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8044 - accuracy: 0.7429 - val_loss: 0.8997 - val_accuracy: 0.6591\n",
      "Epoch 146/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8024 - accuracy: 0.7429 - val_loss: 0.8998 - val_accuracy: 0.6591\n",
      "Epoch 147/200\n",
      "389/389 [==============================] - 1s 1ms/sample - loss: 0.8013 - accuracy: 0.7404 - val_loss: 0.8957 - val_accuracy: 0.6591\n",
      "Epoch 148/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8047 - accuracy: 0.7429 - val_loss: 0.8954 - val_accuracy: 0.6591\n",
      "Epoch 149/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.8035 - accuracy: 0.7429 - val_loss: 0.8907 - val_accuracy: 0.6591\n",
      "Epoch 150/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7946 - accuracy: 0.7429 - val_loss: 0.8835 - val_accuracy: 0.6591\n",
      "Epoch 151/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7889 - accuracy: 0.7429 - val_loss: 0.8832 - val_accuracy: 0.6591\n",
      "Epoch 152/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7838 - accuracy: 0.7429 - val_loss: 0.8789 - val_accuracy: 0.6591\n",
      "Epoch 153/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7822 - accuracy: 0.7429 - val_loss: 0.8786 - val_accuracy: 0.6591\n",
      "Epoch 154/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7807 - accuracy: 0.7429 - val_loss: 0.8753 - val_accuracy: 0.6591\n",
      "Epoch 155/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7736 - accuracy: 0.7429 - val_loss: 0.8773 - val_accuracy: 0.6591\n",
      "Epoch 156/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7797 - accuracy: 0.7429 - val_loss: 0.8773 - val_accuracy: 0.6591\n",
      "Epoch 157/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7753 - accuracy: 0.7429 - val_loss: 0.8753 - val_accuracy: 0.6591\n",
      "Epoch 158/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7752 - accuracy: 0.7429 - val_loss: 0.8827 - val_accuracy: 0.6591\n",
      "Epoch 159/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7791 - accuracy: 0.7429 - val_loss: 0.8869 - val_accuracy: 0.6591\n",
      "Epoch 160/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7814 - accuracy: 0.7429 - val_loss: 0.8826 - val_accuracy: 0.6591\n",
      "Epoch 161/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7746 - accuracy: 0.7429 - val_loss: 0.8813 - val_accuracy: 0.6591\n",
      "Epoch 162/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7684 - accuracy: 0.7429 - val_loss: 0.8774 - val_accuracy: 0.6591\n",
      "Epoch 163/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7741 - accuracy: 0.7429 - val_loss: 0.8756 - val_accuracy: 0.6591\n",
      "Epoch 164/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7800 - accuracy: 0.7429 - val_loss: 0.8765 - val_accuracy: 0.6591\n",
      "Epoch 165/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7735 - accuracy: 0.7429 - val_loss: 0.8811 - val_accuracy: 0.6591\n",
      "Epoch 166/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7824 - accuracy: 0.7429 - val_loss: 0.8805 - val_accuracy: 0.6591\n",
      "Epoch 167/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7872 - accuracy: 0.7429 - val_loss: 0.8783 - val_accuracy: 0.6591\n",
      "Epoch 168/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7780 - accuracy: 0.7455 - val_loss: 0.8790 - val_accuracy: 0.6591\n",
      "Epoch 169/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7746 - accuracy: 0.7429 - val_loss: 0.8740 - val_accuracy: 0.6591\n",
      "Epoch 170/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7727 - accuracy: 0.7429 - val_loss: 0.8727 - val_accuracy: 0.6591\n",
      "Epoch 171/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7656 - accuracy: 0.7455 - val_loss: 0.8780 - val_accuracy: 0.6591\n",
      "Epoch 172/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7711 - accuracy: 0.7378 - val_loss: 0.8766 - val_accuracy: 0.6591\n",
      "Epoch 173/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7769 - accuracy: 0.7455 - val_loss: 0.8750 - val_accuracy: 0.6591\n",
      "Epoch 174/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7714 - accuracy: 0.7429 - val_loss: 0.8730 - val_accuracy: 0.6591\n",
      "Epoch 175/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7698 - accuracy: 0.7455 - val_loss: 0.8688 - val_accuracy: 0.6591\n",
      "Epoch 176/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7793 - accuracy: 0.7429 - val_loss: 0.8693 - val_accuracy: 0.6591\n",
      "Epoch 177/200\n",
      "389/389 [==============================] - 1s 1ms/sample - loss: 0.7828 - accuracy: 0.7429 - val_loss: 0.8717 - val_accuracy: 0.6591\n",
      "Epoch 178/200\n",
      "389/389 [==============================] - 1s 2ms/sample - loss: 0.7791 - accuracy: 0.7429 - val_loss: 0.8806 - val_accuracy: 0.6591\n",
      "Epoch 179/200\n",
      "389/389 [==============================] - 1s 2ms/sample - loss: 0.7916 - accuracy: 0.7429 - val_loss: 0.8918 - val_accuracy: 0.6591\n",
      "Epoch 180/200\n",
      "389/389 [==============================] - 1s 1ms/sample - loss: 0.7914 - accuracy: 0.7429 - val_loss: 0.8883 - val_accuracy: 0.6591\n",
      "Epoch 181/200\n",
      "389/389 [==============================] - 1s 1ms/sample - loss: 0.7906 - accuracy: 0.7429 - val_loss: 0.8804 - val_accuracy: 0.6591\n",
      "Epoch 182/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7835 - accuracy: 0.7429 - val_loss: 0.8726 - val_accuracy: 0.6591\n",
      "Epoch 183/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7749 - accuracy: 0.7429 - val_loss: 0.8638 - val_accuracy: 0.6591\n",
      "Epoch 184/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7777 - accuracy: 0.7429 - val_loss: 0.8599 - val_accuracy: 0.6591\n",
      "Epoch 185/200\n",
      "389/389 [==============================] - 1s 2ms/sample - loss: 0.7658 - accuracy: 0.7429 - val_loss: 0.8568 - val_accuracy: 0.6591\n",
      "Epoch 186/200\n",
      "389/389 [==============================] - 1s 2ms/sample - loss: 0.7671 - accuracy: 0.7429 - val_loss: 0.8575 - val_accuracy: 0.6591\n",
      "Epoch 187/200\n",
      "389/389 [==============================] - 1s 2ms/sample - loss: 0.7587 - accuracy: 0.7429 - val_loss: 0.8548 - val_accuracy: 0.6591\n",
      "Epoch 188/200\n",
      "389/389 [==============================] - 1s 2ms/sample - loss: 0.7675 - accuracy: 0.7429 - val_loss: 0.8539 - val_accuracy: 0.6591\n",
      "Epoch 189/200\n",
      "389/389 [==============================] - 1s 2ms/sample - loss: 0.7692 - accuracy: 0.7429 - val_loss: 0.8550 - val_accuracy: 0.6591\n",
      "Epoch 190/200\n",
      "389/389 [==============================] - 1s 2ms/sample - loss: 0.7583 - accuracy: 0.7429 - val_loss: 0.8588 - val_accuracy: 0.6591\n",
      "Epoch 191/200\n",
      "389/389 [==============================] - 1s 1ms/sample - loss: 0.7680 - accuracy: 0.7429 - val_loss: 0.8610 - val_accuracy: 0.6591\n",
      "Epoch 192/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7656 - accuracy: 0.7455 - val_loss: 0.8598 - val_accuracy: 0.6591\n",
      "Epoch 193/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7619 - accuracy: 0.7429 - val_loss: 0.8570 - val_accuracy: 0.6591\n",
      "Epoch 194/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7665 - accuracy: 0.7429 - val_loss: 0.8542 - val_accuracy: 0.6591\n",
      "Epoch 195/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7636 - accuracy: 0.7429 - val_loss: 0.8530 - val_accuracy: 0.6591\n",
      "Epoch 196/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7591 - accuracy: 0.7429 - val_loss: 0.8551 - val_accuracy: 0.6591\n",
      "Epoch 197/200\n",
      "389/389 [==============================] - 1s 1ms/sample - loss: 0.7690 - accuracy: 0.7429 - val_loss: 0.8554 - val_accuracy: 0.6591\n",
      "Epoch 198/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7627 - accuracy: 0.7429 - val_loss: 0.8573 - val_accuracy: 0.6591\n",
      "Epoch 199/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7565 - accuracy: 0.7429 - val_loss: 0.8594 - val_accuracy: 0.6591\n",
      "Epoch 200/200\n",
      "389/389 [==============================] - 0s 1ms/sample - loss: 0.7580 - accuracy: 0.7429 - val_loss: 0.8572 - val_accuracy: 0.6591\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "109/109 [==============================] - 0s 2ms/sample - loss: 0.7640 - accuracy: 0.7248\n"
     ]
    }
   ],
   "source": [
    "### CLASSIFICATION ###\n",
    "# We use the reduced dataset to train a classifier and compare it against the same classifier trained with the original dataset.\n",
    "\n",
    "# One hot encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "OH_encoder = LabelEncoder()\n",
    "OH_y_train = pd.DataFrame(OH_encoder.fit_transform(y_train))\n",
    "OH_y_test = pd.DataFrame(OH_encoder.transform(y_test))\n",
    "y_train_oh = keras.utils.to_categorical(OH_y_train)\n",
    "y_test_oh = keras.utils.to_categorical(OH_y_test)\n",
    "\n",
    "## Definition of the best classifier obtained previously (CTG_dataset_classification)\n",
    "def build_best_model(dropout: int, l1: int, l2: int, input_shape: int):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(4000, activation=tf.nn.relu ,kernel_regularizer=keras.regularizers.l1_l2(l1,l2), input_shape=(input_shape,)),\n",
    "        layers.Dropout(dropout),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(250,activation=tf.nn.relu, kernel_regularizer=keras.regularizers.l1_l2(l1,l2)),\n",
    "        layers.Dropout(dropout),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(20,activation=tf.nn.relu, kernel_regularizer=keras.regularizers.l1_l2(l1,l2)),\n",
    "        layers.Dropout(dropout),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(2,activation=tf.nn.softmax)\n",
    "      ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Fit best model with dimensionality reduction data\n",
    "model_ae = build_best_model(0.5,0.0001, 0.0001, X_train_encoded.shape[1])\n",
    "history_ae = model_ae.fit(X_train_encoded, y_train_oh, epochs=200,\n",
    "                    validation_split = 0.1, verbose=1, callbacks=[], shuffle=False)\n",
    "hist_pca = pd.DataFrame(history_ae.history)\n",
    "\n",
    "test_loss, test_acc = model_ae.evaluate(X_test_encoded, y_test_oh)\n",
    "\n",
    "# Fit best model with concatenated data\n",
    "#model = build_best_model(0.5,0.0001,0.0001, X_train_norm.shape[1])\n",
    "#history = model.fit(X_train, y_train_oh, epochs=150,\n",
    "#                    validation_split = 0.1, verbose=1, callbacks=[early_stop])\n",
    "#hist = pd.DataFrame(history.history)\n",
    "\n",
    "#test_loss, test_acc = model.evaluate(X_test, y_test_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE silhoutte score: 0.8439498543739319\n",
      "Original silhoutte score: 0.3350685056729452\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###### CLUSTERING ###\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.cm as cm\n",
    "n_clusters = 2\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "dae_cluster_labels = kmeans.fit_predict(X_train_encoded)\n",
    "dae_silhouette_avg = silhouette_score(X_train_encoded, dae_cluster_labels)\n",
    "\n",
    "cluster_labels = kmeans.fit_predict(X_train)\n",
    "silhouette_avg = silhouette_score(X_train, cluster_labels)\n",
    "\n",
    "print(f\"AE silhoutte score: {dae_silhouette_avg}\")\n",
    "print(f\"Original silhoutte score: {silhouette_avg}\")\n",
    "\n",
    "### PLOT SILOHUETTE SCORE FOR CLUSTERS\n",
    "# Create a subplot with 1 row and 2 columns\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.set_size_inches(18, 7)\n",
    "\n",
    "# The 1st subplot is the silhouette plot\n",
    "# The silhouette coefficient can range from -1, 1 but in this example all\n",
    "# lie within [-0.1, 1]\n",
    "ax1.set_xlim([-0.1, 1])\n",
    "# The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "# plots of individual clusters, to demarcate them clearly.\n",
    "ax1.set_ylim([0, len(X_train_encoded) + (n_clusters + 1) * 10])\n",
    "\n",
    "# Compute the silhouette scores for each sample\n",
    "sample_silhouette_values = silhouette_samples(X_train_encoded, dae_cluster_labels)\n",
    "\n",
    "y_lower = 10\n",
    "for i in range(n_clusters):\n",
    "    # Aggregate the silhouette scores for samples belonging to\n",
    "    # cluster i, and sort them\n",
    "    ith_cluster_silhouette_values = \\\n",
    "        sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "    ith_cluster_silhouette_values.sort()\n",
    "\n",
    "    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "    y_upper = y_lower + size_cluster_i\n",
    "\n",
    "    color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "    ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                      0, ith_cluster_silhouette_values,\n",
    "                      facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "    # Label the silhouette plots with their cluster numbers at the middle\n",
    "    ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "    # Compute the new y_lower for next plot\n",
    "    y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "# The vertical line for average silhouette score of all the values\n",
    "ax1.axvline(x=dae_silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "# Compute the silhouette scores for each sample\n",
    "sample_silhouette_values = silhouette_samples(X_train, cluster_labels)\n",
    "\n",
    "y_lower = 10\n",
    "for i in range(n_clusters):\n",
    "    # Aggregate the silhouette scores for samples belonging to\n",
    "    # cluster i, and sort them\n",
    "    ith_cluster_silhouette_values = \\\n",
    "        sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "    ith_cluster_silhouette_values.sort()\n",
    "\n",
    "    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "    y_upper = y_lower + size_cluster_i\n",
    "\n",
    "    color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "    ax2.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                      0, ith_cluster_silhouette_values,\n",
    "                      facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "    # Label the silhouette plots with their cluster numbers at the middle\n",
    "    ax2.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "    # Compute the new y_lower for next plot\n",
    "    y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "ax2.set_title(\"The silhouette plot for the various clusters.\")\n",
    "ax2.set_xlabel(\"The silhouette coefficient values\")\n",
    "ax2.set_ylabel(\"Cluster label\")\n",
    "\n",
    "# The vertical line for average silhouette score of all the values\n",
    "ax2.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "ax2.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "ax2.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Here we trained an autoencoder using a dataset modified with noise, and used the original dataset to force the autoencoder to reconstruct it from a smaller latent space. This lead to a latent space of about 1000 times smaller than the original. When compared using classifiers and clustering methods, there is a drop in accuracy and a significant increase in silhouette score. The dimensionality reduction speeds the classifier training process and enables the training of more complex models in reduced amount of time.\n",
    "\n",
    "Classifier Accuracy:\n",
    "\n",
    "Silhouette Score: 0.8439\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
