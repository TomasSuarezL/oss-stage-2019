{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swapping: 65 rows.\n"
     ]
    }
   ],
   "source": [
    "import Models\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "rn.seed(1)\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "# Load Data\n",
    "X_renal_data = pd.read_csv('./x_exp_renal.csv', sep='\\t') # Dataset has Donor ID as first column\n",
    "y_renal_data = pd.read_csv('./y_renal.csv', sep=',') # Dataset has Donor ID on first column and Label on second column.\n",
    "\n",
    "X_train_norm, X_train_swapped, X_test_norm, y_train, y_test, y_train_oh, y_test_oh, X_train_first, X_train_second, X_swapped_first, X_swapped_second, X_test_first, X_test_second \\\n",
    "    = Models.prepare_datasets(X_renal_data.iloc[:,1:],y_renal_data[\"label\"], test_size=0.2, swap_noise=0.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Hyperparamter tuning\n",
    "# MAP y_train from classes -1 and 1 to 0 and 1\n",
    "y_train_map = ((y_train + 1)/2).astype(int)\n",
    "\n",
    "### VISUALIZATION WITH PCA\n",
    "## ORIGINAL DATASET\n",
    "X_latent_pca, X_latent_test_pca = Models.perform_PCA(X_train_norm, X_test_norm, y_train, y_test, n_components=10)\n",
    "\n",
    "mu=0.5\n",
    "dropouts = [0,0.1,0.2,0.3]\n",
    "l1s = [0.000005]\n",
    "l2s = [0.000005,0.000001,0.00001]\n",
    "scores = []\n",
    "for dropout in dropouts:\n",
    "    for l1 in l1s:\n",
    "        for l2 in l2s:\n",
    "            ## Build and Train Autoencoder\n",
    "            autoencoder, encoder, decoder, loss = Models.build_and_train_multi_autoencoder([X_swapped_first,X_swapped_second],\n",
    "                                                                          [X_train_first,X_train_second],\n",
    "                                                                          encoding_dim=50, \n",
    "                                                                          regularizer=tf.keras.regularizers.l1_l2(l1,l2),\n",
    "                                                                          dropout=dropout,\n",
    "                                                                          epochs=200,\n",
    "                                                                          mu=mu)\n",
    "            ## Encode datasets\n",
    "            X_latent_ae = Models.encode_dataset([X_train_first,X_train_second], encoder)\n",
    "            X_latent_test_ae = Models.encode_dataset([X_test_first,X_test_second], encoder)\n",
    "         \n",
    "            ## PCA ON AUTOENCODER LATENT SPACE\n",
    "            X_latent_pca_ae, X_latent_test_pca_ae = Models.perform_PCA(X_latent_ae, X_latent_test_ae, y_train, y_test, n_components=10)\n",
    "\n",
    "            ### CLASSIFICATION ###\n",
    "            # We use the reduced dataset to train a classifier and compare it against the same classifier trained with the original dataset.\n",
    "            lr_accuracy, svm_accuracy, rf_accuracy = Models.classify(X_latent_ae, X_latent_test_ae, y_train, y_test, model_type=\"AE\")\n",
    "\n",
    "            ### CLUSTERING ###\n",
    "            silhouette_kmeans, mutual_info_kmeans, silhouette_spectral, mutual_info_spectral, silhouette_hierarchical, mutual_info_hierarchical = Models.cluster(X_latent_ae,y_train_map, model_type=\"AE\")\n",
    "\n",
    "            scores.append((dropout,l1,l2,loss,lr_accuracy,svm_accuracy,rf_accuracy, lr_auc, svm_auc, rf_auc,silhouette_kmeans, mutual_info_kmeans, silhouette_spectral, mutual_info_spectral, silhouette_hierarchical, mutual_info_hierarchical))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(scores,\n",
    "                      columns=[\"dropout\",\"l1\",\"l2\",\"loss\",\"LR_accuracy\",\"SVM_accuracy\", \"RF_accuracy\", \"LR_auc\", \"SVM_auc\", \"RF_auc\",\"kmeans_silhouette\",\"kmeans_mutual_info\",\"spectral_silhouette\",\"spectral_mutual_info\",\"hierarchical_silhouette\",\"hierarchical_mutual_info\"])    \n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results\n",
    "\n",
    "| Encoding dim | l1      | l2      | Dropout | Loss   | Accuracy (LR) | Accuracy (SVM) | Accuracy (RF) | ROC-AUC (LR) | ROC-AUC (SVM) | ROC-AUC (RF) | SS (K-means) | MI (K-means) | SS (Spectral) | MI (Spectral) | SS (Hierarch.) | MI (Hierarch.) |\n",
    "|--------------|---------|---------|---------|--------|---------------|----------------|---------------|--------------|---------------|--------------|--------------|--------------|---------------|---------------|----------------|----------------|\n",
    "| 50           | 0.000005| 0.000005| 0.00    | 0.0100 |  0.95         | 0.92           | 0.95          | 0.46         | 0.46          | 0.46         | 0.46         | 0.3263       | 0.51          | 0.0047        | 0.46           | 0.4273         |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
